<h2> About</h2>
This project implements bigram and trigram language models to predict the next word in a given phrase.
It uses the NLTK library and well-known corpora (like Gutenberg, Brown, Webtext, etc.) as training datasets.
The program runs as a console application where the user enters text, and the model predicts the most probable next word.

<h2>Features</h2>

Train bigram and trigram models on NLTK corpora.

Calculate conditional probabilities of words.

Interactive console-based predictions.

Works with multiple corpora (Gutenberg, Brown, Webtext, etc.).

Shows how probability-based text prediction works in NLP.

<h2>Installation</h2>
<h6>Make sure you have Python 3.8+ installed.</h6>

Clone the repository:
```bash
git clone https://github.com/WasifAsad/N-Gram-Language-Model-to-predict-next-word.git
cd N-Gram-Language-Model-to-predict-next-word
```
<h2> Future Improvements</h2>

Add smoothing techniques (Laplace, Kneser-Ney).

Support larger n-grams (4-grams, 5-grams).

Create a simple GUI or web app version.

Allow combining multiple corpora for training.
